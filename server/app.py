"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  SCHNEIDER ELECTRIC AI CODE REVIEWER - PRODUCTION v8.0                      ‚ïë
‚ïë  ‚úÖ RULES INTEGRATED - Uses 2,184 Schneider standards                       ‚ïë
‚ïë  ‚úÖ FAIR SCORING - Balanced penalty system                                  ‚ïë
‚ïë  ‚úÖ ENHANCED ANALYSIS - Rule categorization                                 ‚ïë
‚ïë  ‚úÖ SECURITY HARDENED - Environment validation                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import json
import re
import os
from datetime import datetime
from typing import Dict, List, Tuple
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak
from reportlab.lib.enums import TA_CENTER
from dotenv import load_dotenv
import logging

# Configure logging FIRST - before any imports that use logger
import logging as _logging_setup
_logging_setup.basicConfig(level=_logging_setup.INFO)
logger = _logging_setup.getLogger(__name__)

# Import AI libraries conditionally with proper type handling
openai_client = None
genai_module = None

try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
    # Check OpenAI version to provide helpful warnings
    try:
        openai_version = openai.__version__
        logger.info(f"‚ÑπÔ∏è  OpenAI SDK version: {openai_version}")
        # OpenAI SDK 1.0.0+ uses a different API (no proxies parameter)
        if openai_version.startswith('0.'):
            logger.warning("‚ö†Ô∏è  You're using an older OpenAI SDK. Consider upgrading: pip install --upgrade openai")
    except AttributeError:
        logger.warning("‚ö†Ô∏è  Could not detect OpenAI SDK version")
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None  # type: ignore
    OpenAI = None  # type: ignore
    print("‚ö†Ô∏è  OpenAI not available - install with: pip install openai")

try:
    import google.generativeai as genai
    genai_module = genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None  # type: ignore
    genai_module = None
    print("‚ö†Ô∏è  Gemini not available - install with: pip install google-generativeai")

load_dotenv()

app = Flask(__name__)
CORS(app)

# Configuration
LLM_PROVIDER = os.getenv('LLM_PROVIDER', 'gemini').lower()
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

OPENAI_MODEL = 'gpt-4o'
GEMINI_MODEL = 'gemini-2.0-flash'  # Use -latest for v1 API

# Security: Validate API keys (don't log them!)
if LLM_PROVIDER == 'openai' and not OPENAI_API_KEY:
    logger.error("‚ùå OpenAI selected but no API key found in .env")
if LLM_PROVIDER == 'gemini' and not GEMINI_API_KEY:
    logger.error("‚ùå Gemini selected but no API key found in .env")

# Initialize AI clients
openai_client = None
if LLM_PROVIDER == 'openai' and OPENAI_API_KEY and OPENAI_AVAILABLE:
    try:
        if openai:  # Type guard
            # Some OpenAI SDK versions pass 'proxies' to httpx which no longer accepts it.
            # Monkey-patch httpx to silently drop the 'proxies' kwarg before init.
            import httpx as _httpx
            _orig_sync = _httpx.Client.__init__
            _orig_async = _httpx.AsyncClient.__init__
            def _sync_no_proxies(self, *a, **kw): kw.pop('proxies', None); _orig_sync(self, *a, **kw)
            def _async_no_proxies(self, *a, **kw): kw.pop('proxies', None); _orig_async(self, *a, **kw)
            _httpx.Client.__init__ = _sync_no_proxies
            _httpx.AsyncClient.__init__ = _async_no_proxies

            openai_client = openai.OpenAI(
                api_key=OPENAI_API_KEY,
                timeout=60.0,
                max_retries=2
            )
            logger.info(f"‚úÖ OpenAI initialized: {OPENAI_MODEL}")
    except Exception as e:
        logger.error(f"‚ùå OpenAI init failed: {e}")
        logger.info("‚ÑπÔ∏è  Falling back to Gemini provider")
        LLM_PROVIDER = 'gemini'

if LLM_PROVIDER == 'gemini' and GEMINI_API_KEY and GEMINI_AVAILABLE:
    try:
        if genai_module:  # Type guard
            genai_module.configure(api_key=GEMINI_API_KEY)
            logger.info(f"‚úÖ Gemini initialized: {GEMINI_MODEL}")
    except Exception as e:
        logger.error(f"‚ùå Gemini init failed: {e}")

# Load Schneider Electric Rules
RULES_PATH = 'Extracted_Rules_From_Pdf.json'
ALL_RULES = []
RULE_CATEGORIES = {
    'naming': [],
    'structure': [],
    'security': [],
    'energy': [],
    'general': []
}

try:
    with open(RULES_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)
        ALL_RULES = data.get('rules', [])
        
        # Categorize rules for better organization
        for rule in ALL_RULES:
            rule_text = rule.get('rule', '').lower()
            
            if any(kw in rule_text for kw in ['name', 'identifier', 'prefix', 'hungarian']):
                RULE_CATEGORIES['naming'].append(rule)
            elif any(kw in rule_text for kw in ['structure', 'format', 'indent', 'declaration']):
                RULE_CATEGORIES['structure'].append(rule)
            elif any(kw in rule_text for kw in ['security', 'at ', 'address', 'access']):
                RULE_CATEGORIES['security'].append(rule)
            elif any(kw in rule_text for kw in ['energy', 'optimiz', 'performance', 'efficiency']):
                RULE_CATEGORIES['energy'].append(rule)
            else:
                RULE_CATEGORIES['general'].append(rule)
        
        logger.info(f"‚úÖ Loaded {len(ALL_RULES)} Schneider rules")
        logger.info(f"   üìã Naming: {len(RULE_CATEGORIES['naming'])}")
        logger.info(f"   üìã Structure: {len(RULE_CATEGORIES['structure'])}")
        logger.info(f"   üìã Security: {len(RULE_CATEGORIES['security'])}")
        logger.info(f"   üìã Energy: {len(RULE_CATEGORIES['energy'])}")
        logger.info(f"   üìã General: {len(RULE_CATEGORIES['general'])}")
        
except FileNotFoundError:
    logger.warning(f"‚ö†Ô∏è  Rules file not found: {RULES_PATH}")
except Exception as e:
    logger.error(f"‚ùå Failed to load rules: {e}")

REPORTS_DIR = 'reports'
os.makedirs(REPORTS_DIR, exist_ok=True)


def format_rules_for_prompt(rules: List[Dict], max_rules: int = 40) -> str:
    """Format Schneider rules for AI prompt"""
    if not rules:
        return "No specific rules loaded."
    
    rule_text = "SCHNEIDER ELECTRIC MANDATORY CODING STANDARDS:\n\n"
    
    # Prioritize by category
    priority_order = ['security', 'naming', 'structure', 'energy', 'general']
    rules_added = 0
    
    for category in priority_order:
        cat_rules = RULE_CATEGORIES.get(category, [])
        if not cat_rules:
            continue
            
        rule_text += f"--- {category.upper()} RULES ---\n"
        
        for rule in cat_rules[:min(10, max_rules - rules_added)]:
            rules_added += 1
            rule_text += f"[{rule.get('rule_id', 'N/A')}] {rule.get('rule', '')}\n"
            rule_text += f"  Fix: {rule.get('suggested_fix', 'N/A')}\n\n"
            
            if rules_added >= max_rules:
                break
        
        if rules_added >= max_rules:
            break
    
    rule_text += f"\n(Showing {rules_added} of {len(rules)} total rules)\n"
    return rule_text


def calculate_score(issues: List[Dict]) -> Tuple[int, str]:
    """
    Calculate code quality score with FAIR, BALANCED penalties
    
    Returns:
        Tuple[int, str]: (score, grade_letter)
    """
    if not issues:
        return 100, 'A+'
    
    # Count by severity
    critical_count = sum(1 for i in issues if i.get('severity') == 'critical')
    error_count = sum(1 for i in issues if i.get('severity') == 'error')
    warning_count = sum(1 for i in issues if i.get('severity') == 'warning')
    info_count = sum(1 for i in issues if i.get('severity') == 'info')
    
    # Fair penalty system
    deductions = (
        critical_count * 12 +  # Critical: -12 points
        error_count * 6 +      # Error: -6 points
        warning_count * 3 +    # Warning: -3 points
        info_count * 1         # Info: -1 point
    )
    
    score = max(0, min(100, 100 - deductions))
    
    # Ensure minimum score if code has no critical issues
    if score < 10 and critical_count == 0:
        score = 10
    
    # Determine grade
    if score >= 95:
        grade = 'A+'
    elif score >= 90:
        grade = 'A'
    elif score >= 85:
        grade = 'A-'
    elif score >= 80:
        grade = 'B+'
    elif score >= 75:
        grade = 'B'
    elif score >= 70:
        grade = 'B-'
    elif score >= 65:
        grade = 'C+'
    elif score >= 60:
        grade = 'C'
    elif score >= 50:
        grade = 'D'
    else:
        grade = 'F'
    
    return score, grade


def get_llm_response(prompt: str, system_role: str) -> str:
    """Get AI response with proper error handling"""
    try:
        if LLM_PROVIDER == 'openai' and openai_client:
            response = openai_client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=4000
            )
            content = response.choices[0].message.content
            return content if content else ""
        
        elif LLM_PROVIDER == 'gemini' and genai_module:
            model = genai_module.GenerativeModel(
                model_name=GEMINI_MODEL,
                generation_config={
                    'temperature': 0.1,
                    'max_output_tokens': 4000,
                }
            )
            full_prompt = f"{system_role}\n\n{prompt}"
            response = model.generate_content(full_prompt)
            return response.text
        
        else:
            return "ERROR: No AI provider available"
    
    except Exception as e:
        logger.error(f"‚ùå AI Error: {e}")
        return f"Error: {str(e)}"


def extract_clean_code(ai_response: str, file_ext: str = 'py') -> str:
    """Extract only code from AI response - handles all languages"""
    
    # Language aliases for matching
    lang_aliases = {
        'py': ['python', 'py'],
        'js': ['javascript', 'js'],
        'ts': ['typescript', 'ts'],
        'java': ['java'],
        'c': ['c'],
        'cpp': ['cpp', 'c++', 'cxx'],
        'st': ['st', 'structured-text', 'iecst'],
    }
    
    aliases = lang_aliases.get(file_ext, [file_ext])
    
    # Try specific language patterns first
    for alias in aliases:
        patterns = [
            rf'```{re.escape(alias)}\n(.*?)\n```',
            rf'```{re.escape(alias)}\r\n(.*?)\r\n```',
            rf'```{re.escape(alias)}(.*?)```',
        ]
        for pattern in patterns:
            matches = re.findall(pattern, ai_response, re.DOTALL | re.IGNORECASE)
            if matches:
                return matches[0].strip()
    
    # Try generic code block
    generic = re.findall(r'```\n?(.*?)\n?```', ai_response, re.DOTALL)
    if generic:
        code = generic[0].strip()
        # Remove language tag if it's the first line
        lines = code.split('\n')
        if lines and lines[0].strip().lower() in [a for al in lang_aliases.values() for a in al]:
            code = '\n'.join(lines[1:]).strip()
        return code
    
    # No code blocks - return cleaned response
    skip_phrases = ('here is', "here's", 'certainly', 'sure,', 'of course',
                    "i've", 'below is', 'the following', 'as requested', 'the fixed')
    lines = []
    for line in ai_response.split('\n'):
        stripped = line.lower().strip()
        # Skip language-only lines like "cpp" or "java" at start
        if stripped in [a for al in lang_aliases.values() for a in al]:
            continue
        if not any(stripped.startswith(p) for p in skip_phrases):
            lines.append(line)
    
    result = '\n'.join(lines).strip()
    result = re.sub(r'```\w*', '', result).replace('```', '').strip()
    return result


@app.route('/health', methods=['GET'])
def health_check():
    """Enhanced health check"""
    return jsonify({
        'status': 'healthy',
        'version': '8.0',
        'llm_provider': LLM_PROVIDER,
        'model': OPENAI_MODEL if LLM_PROVIDER == 'openai' else GEMINI_MODEL,
        'rules_loaded': len(ALL_RULES),
        'rules_by_category': {k: len(v) for k, v in RULE_CATEGORIES.items()},
        'rag_enabled': True,
        'features': [
            'schneider_rules_integration',
            'fair_scoring',
            'pdf_reports',
            'auto_fix',
            'chat_assistant',
            'rule_categorization'
        ]
    }), 200


@app.route('/analyze', methods=['POST'])
def analyze_code():
    """
    Analyze code with Schneider Electric rules FULLY INTEGRATED
    """
    try:
        data = request.json
        if not data:
            return jsonify({'error': 'No data provided'}), 400
            
        code = data.get('code', '')
        filename = data.get('filename', 'unknown.py')
        
        if not code:
            return jsonify({'error': 'No code provided'}), 400
        
        file_ext = filename.split('.')[-1].lower()
        
        # Format Schneider rules for prompt
        schneider_rules = format_rules_for_prompt(ALL_RULES, max_rules=40)
        
        # Language specific analysis rules
        lang_analysis_rules = {
            'py': "PEP8 compliance, type hints, docstrings, snake_case naming, no hardcoded secrets",
            'js': "ESLint rules, const/let usage, JSDoc comments, camelCase naming, semicolons, no hardcoded secrets",
            'ts': "TypeScript types on all params/returns, TSDoc, camelCase, access modifiers, no var, no hardcoded secrets",
            'java': "Javadoc on all methods/classes, generics, proper access modifiers, PascalCase classes, camelCase methods, no hardcoded secrets",
            'c': "Function header comments, const usage, indentation, snake_case, no hardcoded secrets",
            'cpp': "Doxygen comments, no 'using namespace std', const references, PascalCase classes, no hardcoded secrets",
            'st': "IEC 61131-3 compliance, variable prefixes (b/i/s/r), indentation inside blocks, comments with (* *), no hardcoded strings",
            'cs': "XML doc comments, access modifiers, PascalCase, proper namespaces, no hardcoded secrets"
        }
        lang_rules = lang_analysis_rules.get(file_ext, "Language best practices, comments, naming conventions, security")

        # ENHANCED SYSTEM PROMPT with rules integration
        system_role = f"""You are a STRICT professional code reviewer for Schneider Electric.

{schneider_rules}

CRITICAL ANALYSIS INSTRUCTIONS:
1. This is {file_ext.upper()} code - apply {file_ext.upper()}-specific standards
2. Check: {lang_rules}
3. Find EVERY violation - be thorough and strict
4. Classify severity:
   - critical: Security risks (hardcoded passwords/keys), crashes, data corruption
   - error: Missing docs/comments, naming violations, missing types, bugs
   - warning: Style issues, potential improvements
   - info: Suggestions, optimizations

Return ONLY a JSON array. No explanation. No markdown.
Format: [{{"rule": "RULE-ID", "message": "description", "line": 1, "severity": "error", "fix": "how to fix", "category": "naming"}}]
If truly no issues: []"""

        prompt = f"""Analyze this {file_ext.upper()} code with MAXIMUM STRICTNESS:

```{file_ext}
{code}
```

Check for ALL of these in {file_ext.upper()} code:
1. Missing comments/docstrings on functions and classes
2. Spacing problems (no spaces around operators, after commas)  
3. Indentation issues
4. Naming convention violations
5. Security issues (hardcoded passwords, secrets, API keys)
6. Missing type annotations/hints
7. Any other {file_ext.upper()} best practice violations

Return ONLY a JSON array (absolutely no other text):
[{{"rule": "DOC-001", "message": "Missing docstring on function calculateEnergy", "line": 1, "severity": "error", "fix": "Add function documentation", "category": "documentation"}}]

BE EXTREMELY STRICT - this code should score LOW before fixing!"""

        # Get AI analysis
        logger.info(f"Analyzing {filename} ({len(code)} chars)")
        ai_response = get_llm_response(prompt, system_role)
        
        # Parse JSON - robust extraction
        issues = []
        try:
            # First try: direct JSON parse
            stripped = ai_response.strip()
            if stripped.startswith('['):
                issues = json.loads(stripped)
            else:
                # Second try: find JSON array in response
                json_match = re.search(r'\[[\s\S]*?\](?=\s*$)', ai_response)
                if not json_match:
                    json_match = re.search(r'\[[\s\S]*\]', ai_response)
                if json_match:
                    issues = json.loads(json_match.group(0))
            
            # Validate - must be a list
            if not isinstance(issues, list):
                issues = []
                
            # Ensure each issue has required fields
            valid_issues = []
            for issue in issues:
                if isinstance(issue, dict) and issue.get('message'):
                    valid_issues.append({
                        'rule': issue.get('rule', 'QUALITY'),
                        'message': issue.get('message', ''),
                        'line': issue.get('line', 1),
                        'severity': issue.get('severity', 'warning'),
                        'fix': issue.get('fix', ''),
                        'category': issue.get('category', 'general')
                    })
            issues = valid_issues
            
        except Exception as e:
            logger.error(f"JSON parse error: {e}")
            logger.error(f"AI response was: {ai_response[:200]}")
            issues = []
        
        # Calculate FAIR score
        score, grade = calculate_score(issues)
        
        logger.info(f"Analysis complete: {len(issues)} issues, Score: {score}/100 ({grade})")
        
        return jsonify({
            'success': True,
            'issues': issues,
            'score': score,
            'grade': grade,
            'file_type': file_ext,
            'rules_checked': len(ALL_RULES),
            'statistics': {
                'critical': sum(1 for i in issues if i.get('severity') == 'critical'),
                'errors': sum(1 for i in issues if i.get('severity') == 'error'),
                'warnings': sum(1 for i in issues if i.get('severity') == 'warning'),
                'info': sum(1 for i in issues if i.get('severity') == 'info')
            }
        }), 200
    
    except Exception as e:
        logger.error(f"Analysis error: {e}")
        return jsonify({'error': str(e)}), 500


def get_language_fix_rules(file_ext: str) -> str:
    """Return language-specific fix rules for perfect score"""
    rules = {
        'py': """- Add module docstring at top: \"\"\"Module description.\"\"\"
- Add type hints: def func(x: float, y: float) -> float:
- Add docstrings to every function, class, __init__
- 4-space indentation, no tabs
- Spaces around operators: x = y * z (not x=y*z)
- Spaces after commas: func(a, b, c)
- 2 blank lines between top-level functions/classes
- 1 blank line between class methods
- snake_case for functions/variables, PascalCase for classes
- Remove hardcoded passwords - use os.getenv() instead""",

        'js': """- Use const/let instead of var
- Add JSDoc comments: /** @param {number} x @returns {number} */
- Add semicolons at end of statements
- Spaces around operators and after commas
- Remove hardcoded secrets - use process.env instead
- camelCase for functions/variables, PascalCase for classes
- Consistent braces and indentation (2 spaces)""",

        'ts': """- Add TypeScript types to ALL parameters: (x: number, y: number): number
- Add return types to all functions
- Use const/let instead of var
- Add JSDoc/TSDoc comments to all functions and classes
- PascalCase for class names, camelCase for functions/variables
- Use private/public access modifiers in classes
- Remove hardcoded secrets - use process.env instead
- Add interface definitions where appropriate
- Semicolons at end of statements""",

        'java': """- Add Javadoc to every class and method: /** description @param @return */
- Use proper access modifiers (private fields, public methods)
- Use generics: ArrayList<Integer> not raw ArrayList
- PascalCase for classes, camelCase for methods/variables
- Hungarian notation for Schneider: str prefix for strings, int for integers
- Remove hardcoded passwords - use environment config
- Add proper spacing around operators and after commas""",

        'c': """- Add file header comment block
- Add function documentation comments
- Add header guards if needed
- Consistent indentation (4 spaces)
- Spaces around operators and after commas
- Remove hardcoded passwords - use config constants
- Use const for constant values
- snake_case for all identifiers""",

        'cpp': """- Remove 'using namespace std;' - use std:: prefix instead
- Add Doxygen comments to class and all methods
- Add proper access modifiers
- Spaces around operators and after commas
- Use const references where appropriate
- Remove hardcoded passwords - use config constants
- PascalCase for classes, camelCase for methods""",

        'st': """- Add comment blocks using (* ... *) syntax NOT Python docstrings
- Use proper IEC 61131-3 naming: prefix variables (b for BOOL, i for INT, s for STRING)
- Add indentation inside IF/FOR/WHILE blocks (3 spaces)
- Remove hardcoded passwords from VAR section
- Add descriptive comments before each section
- Use UPPERCASE for keywords: IF, THEN, END_IF, FOR, DO, END_FOR
- Variable declarations should have inline comments"""
    }
    return rules.get(file_ext, "- Follow language best practices and add documentation")


@app.route('/fix', methods=['POST'])
def fix_code():
    """Fix code with Schneider rules context"""
    try:
        data = request.json
        if not data:
            return jsonify({'error': 'No data'}), 400
            
        code = data.get('code', '')
        error = data.get('error', '')
        issues = data.get('issues', [])
        
        file_ext = 'st' if 'VAR' in code.upper() else 'py'
        
        # Include relevant rules in fix prompt
        relevant_rules = ""
        if issues:
            rule_ids = [i.get('rule', '') for i in issues if i.get('rule')]
            for rule in ALL_RULES[:50]:  # Check first 50 rules
                if rule.get('rule_id') in rule_ids:
                    relevant_rules += f"[{rule['rule_id']}] {rule['rule']}\n  Fix: {rule['suggested_fix']}\n\n"
        
        # Determine language name for prompt
        lang_names = {
            'py': 'Python', 'js': 'JavaScript', 'ts': 'TypeScript',
            'java': 'Java', 'c': 'C', 'cpp': 'C++', 'st': 'Structured Text (IEC 61131-3)',
            'cs': 'C#'
        }
        lang_name = lang_names.get(file_ext, file_ext.upper())

        system_role = f"""You are an EXPERT {lang_name} code fixer for Schneider Electric.
Your goal is to produce PERFECT {lang_name} code that scores 100/100.

ABSOLUTE RULES:
1. Output ONLY valid {lang_name} code - NO other language
2. NO markdown, NO backticks, NO explanations - raw {lang_name} code only
3. Keep ALL original function names, class names, variable names, and logic
4. Fix ALL quality issues to achieve 100/100 score

FOR {lang_name.upper()} SPECIFICALLY FIX:
{get_language_fix_rules(file_ext)}"""

        prompt = f"""Transform this {lang_name} code into PERFECT Schneider Electric compliant code.

ORIGINAL {lang_name.upper()} CODE:
{code}

ISSUES TO FIX:
{chr(10).join([f"- Line {i.get('line','?')}: {i.get('message','')} ‚Üí {i.get('fix','')}" for i in issues]) if issues else error}

CRITICAL: Return ONLY raw {lang_name} code. No backticks. No markdown. No explanations.
The output must be directly saveable as a .{file_ext} file."""

        ai_response = get_llm_response(prompt, system_role)
        fixed_code = extract_clean_code(ai_response, file_ext)
        
        if not fixed_code or len(fixed_code) < 5:
            fixed_code = code
        
        return jsonify({
            'success': True,
            'fixed_code': fixed_code
        }), 200
    
    except Exception as e:
        logger.error(f"Fix error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/chat', methods=['POST'])
def chat():
    """AI chat with Schneider rules context - gives ACTIONABLE fixes"""
    try:
        data = request.json
        if not data:
            return jsonify({'error': 'No data'}), 400
            
        message = data.get('message', '')
        context = data.get('context', '')
        
        system_role = """You are a helpful Schneider Electric code review assistant.

IMPORTANT: When users ask "can you fix it?" or similar:
1. Show SPECIFIC code changes with BEFORE/AFTER examples
2. Give LINE-BY-LINE fixes
3. Be concise but complete
4. Use markdown code blocks

Example response format:
**Fix for Line 1:**
```python
# Before:
def calc(x,y):

# After:
def calc(x: float, y: float) -> float:
    '''Calculate result of x * y'''
```

Be helpful, specific, and actionable!"""
        
        prompt = f"{context}\n\nUser Question: {message}\n\nProvide SPECIFIC fixes with code examples."
        
        reply = get_llm_response(prompt, system_role)
        
        return jsonify({'success': True, 'reply': reply}), 200
    
    except Exception as e:
        logger.error(f"Chat error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/generate_report', methods=['POST'])
def generate_report():
    """Generate ENHANCED PDF report with Schneider branding"""
    try:
        data = request.json
        if not data:
            return jsonify({'error': 'No data'}), 400
            
        issues = data.get('issues', [])
        score = data.get('score', 0)
        filename = data.get('filename', 'analysis')
        code = data.get('code', '')
        grade = data.get('grade', 'N/A')
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f"Schneider_Audit_{filename.replace('.', '_')}_{timestamp}.pdf"
        report_path = os.path.join(REPORTS_DIR, report_filename)
        
        doc = SimpleDocTemplate(report_path, pagesize=A4)
        story = []
        styles = getSampleStyleSheet()
        
        # Title
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=28,
            textColor=colors.HexColor('#3DCD58'),
            alignment=TA_CENTER,
            spaceAfter=20
        )
        
        story.append(Paragraph("‚ö° SCHNEIDER ELECTRIC", title_style))
        story.append(Paragraph("EcoStruxure‚Ñ¢ AI Code Audit Report", styles['Heading2']))
        story.append(Spacer(1, 0.5*inch))
        
        # Executive Summary
        summary_style = ParagraphStyle(
            'Summary',
            parent=styles['Normal'],
            fontSize=11,
            textColor=colors.HexColor('#333333')
        )
        
        summary_text = f"""
        This automated audit was conducted using Schneider Electric's AI-powered code 
        review system, analyzing {len(ALL_RULES)} organizational coding standards 
        including IEC 61131-3 compliance, energy efficiency guidelines, and security protocols.
        """
        story.append(Paragraph(summary_text, summary_style))
        story.append(Spacer(1, 0.3*inch))
        
        # Metadata table
        metadata = [
            ['Report Generated:', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
            ['File Analyzed:', filename],
            ['Lines of Code:', str(len(code.split('\n')))],
            ['Quality Score:', f"{score}/100 ({grade})"],
            ['Issues Found:', str(len(issues))],
            ['Rules Checked:', str(len(ALL_RULES))],
            ['Analysis Engine:', f"{LLM_PROVIDER.upper()} ({OPENAI_MODEL if LLM_PROVIDER == 'openai' else GEMINI_MODEL})"]
        ]
        
        meta_table = Table(metadata, colWidths=[2.5*inch, 3.5*inch])
        meta_table.setStyle(TableStyle([
            ('BACKGROUND', (0,0), (0,-1), colors.HexColor('#F0F0F0')),
            ('TEXTCOLOR', (0,0), (-1,-1), colors.black),
            ('ALIGN', (0,0), (-1,-1), 'LEFT'),
            ('FONTNAME', (0,0), (0,-1), 'Helvetica-Bold'),
            ('FONTSIZE', (0,0), (-1,-1), 10),
            ('GRID', (0,0), (-1,-1), 0.5, colors.grey),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
        ]))
        story.append(meta_table)
        story.append(Spacer(1, 0.4*inch))
        
        # Compliance Status
        if score >= 90:
            status = "EXCELLENT - FULLY COMPLIANT ‚úì"
            status_color = colors.HexColor('#00A651')
        elif score >= 80:
            status = "GOOD - COMPLIANT ‚úì"
            status_color = colors.HexColor('#3DCD58')
        elif score >= 60:
            status = "ACCEPTABLE - NEEDS IMPROVEMENT"
            status_color = colors.HexColor('#FF8C00')
        else:
            status = "NON-COMPLIANT - ACTION REQUIRED"
            status_color = colors.HexColor('#DC143C')
        
        status_data = [
            ['Compliance Status:', status],
            ['Quality Grade:', grade],
            ['Overall Score:', f"{score}/100"]
        ]
        
        status_table = Table(status_data, colWidths=[2.5*inch, 3.5*inch])
        status_table.setStyle(TableStyle([
            ('BACKGROUND', (0,0), (-1,-1), colors.HexColor('#FAFAFA')),
            ('TEXTCOLOR', (1,0), (1,0), status_color),
            ('FONTNAME', (0,0), (0,-1), 'Helvetica-Bold'),
            ('FONTNAME', (1,0), (1,-1), 'Helvetica-Bold'),
            ('FONTSIZE', (1,0), (1,0), 14),
            ('FONTSIZE', (0,0), (-1,-1), 11),
            ('GRID', (0,0), (-1,-1), 1, colors.grey),
            ('ALIGN', (0,0), (-1,-1), 'LEFT'),
            ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
            ('TOPPADDING', (0,0), (-1,-1), 12),
            ('BOTTOMPADDING', (0,0), (-1,-1), 12),
        ]))
        story.append(status_table)
        story.append(Spacer(1, 0.4*inch))
        
        # Issue Statistics
        if issues:
            stats = {
                'Critical': sum(1 for i in issues if i.get('severity') == 'critical'),
                'Errors': sum(1 for i in issues if i.get('severity') == 'error'),
                'Warnings': sum(1 for i in issues if i.get('severity') == 'warning'),
                'Info': sum(1 for i in issues if i.get('severity') == 'info')
            }
            
            story.append(Paragraph("Issue Breakdown", styles['Heading3']))
            stats_data = [['Severity', 'Count', 'Impact']]
            
            for sev, count in stats.items():
                if count > 0:
                    if sev == 'Critical':
                        impact = 'High Risk'
                    elif sev == 'Errors':
                        impact = 'Medium Risk'
                    elif sev == 'Warnings':
                        impact = 'Low Risk'
                    else:
                        impact = 'Informational'
                    stats_data.append([sev, str(count), impact])
            
            stats_table = Table(stats_data, colWidths=[2*inch, 1.5*inch, 2.5*inch])
            stats_table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.HexColor('#3DCD58')),
                ('TEXTCOLOR', (0,0), (-1,0), colors.white),
                ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),
                ('FONTSIZE', (0,0), (-1,0), 11),
                ('GRID', (0,0), (-1,-1), 0.5, colors.grey),
                ('ROWBACKGROUNDS', (0,1), (-1,-1), [colors.white, colors.HexColor('#F5F5F5')]),
                ('ALIGN', (1,1), (1,-1), 'CENTER'),
            ]))
            story.append(stats_table)
            story.append(Spacer(1, 0.4*inch))
            
            # Detailed Issues
            story.append(Paragraph("Detailed Findings", styles['Heading3']))
            story.append(Spacer(1, 0.2*inch))
            
            issues_data = [['#', 'Rule', 'Severity', 'Message', 'Line']]
            
            for idx, issue in enumerate(issues, 1):
                issues_data.append([
                    str(idx),
                    str(issue.get('rule', 'N/A'))[:12],
                    str(issue.get('severity', 'info')).title(),
                    str(issue.get('message', ''))[:60],
                    str(issue.get('line', '-'))
                ])
            
            issues_table = Table(issues_data, colWidths=[0.4*inch, 0.8*inch, 0.8*inch, 3.5*inch, 0.5*inch])
            issues_table.setStyle(TableStyle([
                ('BACKGROUND', (0,0), (-1,0), colors.HexColor('#3DCD58')),
                ('TEXTCOLOR', (0,0), (-1,0), colors.white),
                ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),
                ('FONTSIZE', (0,0), (-1,-1), 9),
                ('GRID', (0,0), (-1,-1), 0.5, colors.grey),
                ('ROWBACKGROUNDS', (0,1), (-1,-1), [colors.white, colors.HexColor('#F9F9F9')]),
                ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
                ('ALIGN', (0,1), (0,-1), 'CENTER'),
                ('ALIGN', (4,1), (4,-1), 'CENTER'),
            ]))
            story.append(issues_table)
        else:
            story.append(Paragraph("‚úì Excellent! No issues found.", styles['Normal']))
            story.append(Paragraph("Code fully complies with all Schneider Electric standards.", styles['Normal']))
        
        story.append(PageBreak())
        
        # Recommendations
        story.append(Paragraph("Recommendations & Next Steps", styles['Heading3']))
        story.append(Spacer(1, 0.2*inch))
        
        if score >= 90:
            recs = [
                "‚Ä¢ Continue maintaining high code quality standards",
                "‚Ä¢ Consider peer code reviews for knowledge sharing",
                "‚Ä¢ Document best practices for team reference"
            ]
        elif score >= 70:
            recs = [
                "‚Ä¢ Address all critical and high-priority issues",
                "‚Ä¢ Review Schneider coding guidelines documentation",
                "‚Ä¢ Schedule follow-up audit after corrections"
            ]
        else:
            recs = [
                "‚Ä¢ URGENT: Fix all critical security and compliance issues",
                "‚Ä¢ Request technical review with senior developer",
                "‚Ä¢ Attend Schneider coding standards training",
                "‚Ä¢ Re-audit after major corrections"
            ]
        
        for rec in recs:
            story.append(Paragraph(rec, styles['Normal']))
            story.append(Spacer(1, 0.1*inch))
        
        story.append(Spacer(1, 0.3*inch))
        
        # Footer
        footer_style = ParagraphStyle(
            'Footer',
            parent=styles['Normal'],
            fontSize=9,
            textColor=colors.grey,
            alignment=TA_CENTER
        )
        story.append(Spacer(1, 0.5*inch))
        story.append(Paragraph("‚îÅ" * 80, footer_style))
        story.append(Paragraph(
            "This report is generated by Schneider Electric AI Code Reviewer v8.0",
            footer_style
        ))
        story.append(Paragraph(
            "For questions or support, contact your Schneider Electric technical lead",
            footer_style
        ))
        
        # Build PDF
        doc.build(story)
        
        logger.info(f"‚úÖ Report generated: {report_filename}")
        
        return jsonify({
            'success': True,
            'filename': report_filename,
            'path': report_path,
            'download_url': f'/download_report/{report_filename}'
        }), 200
    
    except Exception as e:
        logger.error(f"Report generation error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/download_report/<filename>', methods=['GET'])
def download_report(filename):
    """Download report"""
    try:
        file_path = os.path.join(REPORTS_DIR, filename)
        if os.path.exists(file_path):
            return send_file(file_path, as_attachment=True, download_name=filename)
        return jsonify({'error': 'Report not found'}), 404
    except Exception as e:
        logger.error(f"Download error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/rules', methods=['GET'])
def get_rules():
    """Get all Schneider rules (for dashboard/UI)"""
    try:
        category = request.args.get('category', 'all')
        
        if category == 'all':
            return jsonify({
                'success': True,
                'rules': ALL_RULES,
                'total': len(ALL_RULES)
            }), 200
        elif category in RULE_CATEGORIES:
            return jsonify({
                'success': True,
                'rules': RULE_CATEGORIES[category],
                'total': len(RULE_CATEGORIES[category]),
                'category': category
            }), 200
        else:
            return jsonify({'error': 'Invalid category'}), 400
            
    except Exception as e:
        logger.error(f"Rules fetch error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/statistics', methods=['GET'])
def get_statistics():
    """Get system statistics"""
    try:
        return jsonify({
            'success': True,
            'statistics': {
                'total_rules': len(ALL_RULES),
                'rule_categories': {k: len(v) for k, v in RULE_CATEGORIES.items()},
                'llm_provider': LLM_PROVIDER,
                'model': OPENAI_MODEL if LLM_PROVIDER == 'openai' else GEMINI_MODEL,
                'version': '8.0',
                'features': [
                    'Schneider Rules Integration',
                    'Fair Scoring System',
                    'PDF Report Generation',
                    'Auto-Fix Capability',
                    'AI Chat Assistant',
                    'Rule Categorization'
                ]
            }
        }), 200
    except Exception as e:
        logger.error(f"Statistics error: {e}")
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    print("=" * 80)
    print("üèÜ SCHNEIDER ELECTRIC AI CODE REVIEWER - PRODUCTION v8.0")
    print("=" * 80)
    print(f"‚úÖ AI Provider: {LLM_PROVIDER.upper()}")
    print(f"‚úÖ Model: {OPENAI_MODEL if LLM_PROVIDER == 'openai' else GEMINI_MODEL}")
    print(f"‚úÖ Schneider Rules: {len(ALL_RULES)}")
    print(f"   üìã Naming: {len(RULE_CATEGORIES['naming'])}")
    print(f"   üìã Structure: {len(RULE_CATEGORIES['structure'])}")
    print(f"   üìã Security: {len(RULE_CATEGORIES['security'])}")
    print(f"   üìã Energy: {len(RULE_CATEGORIES['energy'])}")
    print(f"   üìã General: {len(RULE_CATEGORIES['general'])}")
    print(f"‚úÖ Scoring: Fair & Balanced System")
    print(f"‚úÖ Reports: Enhanced PDF Generation")
    print("üöÄ Server: http://localhost:5000")
    print("=" * 80)
    
    app.run(debug=True, host='0.0.0.0', port=5000)